{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1375140,"sourceType":"datasetVersion","datasetId":801979}],"dockerImageVersionId":30066,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn.preprocessing\nimport seaborn as sns\nimport plotly.graph_objects as go\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-02T03:06:24.15471Z","iopub.execute_input":"2024-02-02T03:06:24.155322Z","iopub.status.idle":"2024-02-02T03:06:25.218237Z","shell.execute_reply.started":"2024-02-02T03:06:24.155215Z","shell.execute_reply":"2024-02-02T03:06:25.217337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install openpyxl","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:06:25.220091Z","iopub.execute_input":"2024-02-02T03:06:25.220446Z","iopub.status.idle":"2024-02-02T03:06:35.729766Z","shell.execute_reply.started":"2024-02-02T03:06:25.220409Z","shell.execute_reply":"2024-02-02T03:06:35.728696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.style.use('ggplot')","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:06:35.731095Z","iopub.execute_input":"2024-02-02T03:06:35.731405Z","iopub.status.idle":"2024-02-02T03:06:35.737798Z","shell.execute_reply.started":"2024-02-02T03:06:35.731372Z","shell.execute_reply":"2024-02-02T03:06:35.736647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading the data\npath = '/kaggle/input/anomaly-detection-smart-meter-data-sample/Lastgang Elektroverbruche 160101-170511.xlsx'\ndf = pd.read_excel(path, engine='openpyxl', index_col=0)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:06:35.739695Z","iopub.execute_input":"2024-02-02T03:06:35.740051Z","iopub.status.idle":"2024-02-02T03:06:40.074584Z","shell.execute_reply.started":"2024-02-02T03:06:35.740017Z","shell.execute_reply":"2024-02-02T03:06:40.073459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:06:40.078125Z","iopub.execute_input":"2024-02-02T03:06:40.078465Z","iopub.status.idle":"2024-02-02T03:06:40.091183Z","shell.execute_reply.started":"2024-02-02T03:06:40.078431Z","shell.execute_reply":"2024-02-02T03:06:40.090286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#renaming the columns\ndf.index.name ='datetime'\ndf.columns = ['energy']\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:06:40.092966Z","iopub.execute_input":"2024-02-02T03:06:40.093293Z","iopub.status.idle":"2024-02-02T03:06:40.109347Z","shell.execute_reply.started":"2024-02-02T03:06:40.09326Z","shell.execute_reply":"2024-02-02T03:06:40.108411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['date'] = df.index.date\ndf['time'] = df.index.time\ndf['year'] = df.index.year\ndf['weekday'] = df.index.strftime(\"%A\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:06:40.110793Z","iopub.execute_input":"2024-02-02T03:06:40.111127Z","iopub.status.idle":"2024-02-02T03:06:40.582659Z","shell.execute_reply.started":"2024-02-02T03:06:40.111095Z","shell.execute_reply":"2024-02-02T03:06:40.581675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Entire load curve and the daily load trends\n_ = df.pivot_table(index=df.index, \n                     values='energy').plot(figsize=(15,4),\n                     title='Entire Load Curve')\n_ = df.pivot_table(index=df['time'], \n                     values='energy',\n                     aggfunc=np.mean).plot(figsize=(15,4),\n                     title='Daily Load Trends')","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:06:40.584554Z","iopub.execute_input":"2024-02-02T03:06:40.585013Z","iopub.status.idle":"2024-02-02T03:06:41.468546Z","shell.execute_reply.started":"2024-02-02T03:06:40.584968Z","shell.execute_reply":"2024-02-02T03:06:41.467585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load distributions & daily load curve\n_ = df['energy'].plot.hist(figsize=(15, 5), bins=100, title='Load Distribution')\n\n_ = df.pivot_table(index=df['time'], \n                     columns='weekday', \n                     values='energy',\n                     aggfunc=np.mean).plot(figsize=(15,4),\n                     title='Energy Daily Load Curve Trends')","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:06:41.469989Z","iopub.execute_input":"2024-02-02T03:06:41.470332Z","iopub.status.idle":"2024-02-02T03:06:42.217232Z","shell.execute_reply.started":"2024-02-02T03:06:41.470297Z","shell.execute_reply":"2024-02-02T03:06:42.216408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#normalize the energy data\ndef normalize_data(df):\n    scaler = sklearn.preprocessing.MinMaxScaler()\n    df['energy']=scaler.fit_transform(df['energy'].values.reshape(-1,1))\n    return df\n\ndf_norm = normalize_data(df)\ndf_norm = df_norm.drop(columns=['date','time','year','weekday'])\ndf_norm.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:06:42.218382Z","iopub.execute_input":"2024-02-02T03:06:42.218882Z","iopub.status.idle":"2024-02-02T03:06:42.230224Z","shell.execute_reply.started":"2024-02-02T03:06:42.218844Z","shell.execute_reply":"2024-02-02T03:06:42.229113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_norm.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:06:42.231549Z","iopub.execute_input":"2024-02-02T03:06:42.231943Z","iopub.status.idle":"2024-02-02T03:06:42.244485Z","shell.execute_reply.started":"2024-02-02T03:06:42.231906Z","shell.execute_reply":"2024-02-02T03:06:42.243461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple RNN Model by ignoring the anomalies","metadata":{}},{"cell_type":"code","source":"#data_loading\ndef load_data(stock, seq_len):\n    X_train = []\n    y_train = []\n    for i in range(seq_len, len(stock)):\n        X_train.append(stock.iloc[i-seq_len : i, 0])\n        y_train.append(stock.iloc[i, 0])\n    \n    X_test = X_train[40000:]             \n    y_test = y_train[40000:]\n    \n    X_train = X_train[:40000]           \n    y_train = y_train[:40000]\n    \n    X_train = np.array(X_train)\n    y_train = np.array(y_train)\n    \n    X_test = np.array(X_test)\n    y_test = np.array(y_test)\n    \n    #4 reshape data to input into RNN models\n    X_train = np.reshape(X_train, (40000, seq_len, 1))\n    X_test = np.reshape(X_test, (X_test.shape[0], seq_len, 1))\n    \n    return [X_train, y_train, X_test, y_test]","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:06:42.245918Z","iopub.execute_input":"2024-02-02T03:06:42.246238Z","iopub.status.idle":"2024-02-02T03:06:42.257408Z","shell.execute_reply.started":"2024-02-02T03:06:42.246207Z","shell.execute_reply":"2024-02-02T03:06:42.256233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seq_len = 20\n\nX_train, y_train, X_test, y_test = load_data(df_norm, seq_len)\n\nprint('X_train.shape = ',X_train.shape)\nprint('y_train.shape = ', y_train.shape)\nprint('X_test.shape = ', X_test.shape)\nprint('y_test.shape = ',y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:06:42.259144Z","iopub.execute_input":"2024-02-02T03:06:42.25952Z","iopub.status.idle":"2024-02-02T03:06:56.079852Z","shell.execute_reply.started":"2024-02-02T03:06:42.259486Z","shell.execute_reply":"2024-02-02T03:06:56.078446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\nfrom keras.layers import Dense,Dropout,SimpleRNN,LSTM\nfrom keras.models import Sequential\n\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.metrics import confusion_matrix\n\n\nfrom keras.layers import Conv1D, MaxPooling1D, Flatten\n\ncnn_model = Sequential()\n\ncnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\ncnn_model.add(MaxPooling1D(pool_size=2))\ncnn_model.add(Dropout(0.15))\n\ncnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\ncnn_model.add(MaxPooling1D(pool_size=2))\ncnn_model.add(Dropout(0.15))\n\ncnn_model.add(Flatten())\ncnn_model.add(Dense(1))\n\ncnn_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:08:08.127959Z","iopub.execute_input":"2024-02-02T03:08:08.128367Z","iopub.status.idle":"2024-02-02T03:08:08.212257Z","shell.execute_reply.started":"2024-02-02T03:08:08.128333Z","shell.execute_reply":"2024-02-02T03:08:08.211076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_model.compile(optimizer=\"adam\", loss=\"MSE\")\ncnn_model.fit(X_train, y_train, epochs=10, batch_size=80)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:08:16.498553Z","iopub.execute_input":"2024-02-02T03:08:16.49899Z","iopub.status.idle":"2024-02-02T03:08:41.69573Z","shell.execute_reply.started":"2024-02-02T03:08:16.49895Z","shell.execute_reply":"2024-02-02T03:08:41.694659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions using the CNN model\ncnn_predictions = cnn_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:08:54.416126Z","iopub.execute_input":"2024-02-02T03:08:54.416572Z","iopub.status.idle":"2024-02-02T03:08:54.71615Z","shell.execute_reply.started":"2024-02-02T03:08:54.41653Z","shell.execute_reply":"2024-02-02T03:08:54.715124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the CNN model using R2 Score and MSE\ncnn_r2 = r2_score(y_test, cnn_predictions)\ncnn_mse = mean_squared_error(y_test, cnn_predictions)\n\nprint(f'CNN Model R2 Score: {cnn_r2}')\nprint(f'CNN Model MSE: {cnn_mse}')\n\ndef plot_predictions(test, predicted, title):\n    plt.figure(figsize=(16,4))\n    plt.plot(test, color='blue',label='Actual power consumption data')\n    plt.plot(predicted, alpha=0.7, color='orange',label='Predicted power consumption data')\n    plt.title(title)\n    plt.xlabel('Time')\n    plt.ylabel('Normalized power consumption scale')\n    plt.legend()\n    plt.show()\n\n# Plot predictions using the CNN model\nplot_predictions(y_test, cnn_predictions, \"Load Predictions Validation - CNN\")\n\nthreshold_high = 0.5  # Adjust this threshold based on your problem\n\n# Convert regression predictions to classification labels\ncnn_class_predictions = np.where(cnn_predictions > threshold_high, 1, 0)\ny_test_class = np.where(y_test > threshold_high, 1, 0)\n\n# Calculate and display confusion matrix\nconf_matrix = confusion_matrix(y_test_class, cnn_class_predictions)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:10:12.498111Z","iopub.execute_input":"2024-02-02T03:10:12.498512Z","iopub.status.idle":"2024-02-02T03:10:12.880099Z","shell.execute_reply.started":"2024-02-02T03:10:12.498475Z","shell.execute_reply":"2024-02-02T03:10:12.87898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nthreshold_high = 0.5\ncnn_pred_classes = (cnn_predictions > threshold_high).astype(int)\ny_test_class = (y_test > threshold_high).astype(int)\n\n# Evaluation metrics\ncnn_r2 = r2_score(y_test, cnn_predictions)\ncnn_conf_matrix = confusion_matrix(y_test_class, cnn_pred_classes)\n\nprint(\"CNN Model R2 Score:\", cnn_r2)\nprint(\"Confusion Matrix:\")\nprint(cnn_conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test_class, cnn_pred_classes))\n\n# Plot confusion matrix\nplt.figure(figsize=(6, 6))\nsns.heatmap(cnn_conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\nplt.title('Confusion Matrix - CNN Model')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:15:54.417041Z","iopub.execute_input":"2024-02-02T03:15:54.41806Z","iopub.status.idle":"2024-02-02T03:15:54.588778Z","shell.execute_reply.started":"2024-02-02T03:15:54.418001Z","shell.execute_reply":"2024-02-02T03:15:54.587908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score, confusion_matrix, classification_report\n\nfrom keras.layers import Conv1D, MaxPooling1D, Flatten, Dropout\nfrom keras.models import Sequential\n\n# Function to plot predictions\ndef plot_predictions(test, predicted, title):\n    plt.figure(figsize=(16, 4))\n    plt.plot(test, color='blue', label='Actual power consumption data')\n    plt.plot(predicted, alpha=0.7, color='orange', label='Predicted power consumption data')\n    plt.title(title)\n    plt.xlabel('Time')\n    plt.ylabel('Normalized power consumption scale')\n    plt.legend()\n    plt.show()\n\n# Convert the RNN model to a CNN model\ncnn_model = Sequential()\n\ncnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\ncnn_model.add(MaxPooling1D(pool_size=2))\ncnn_model.add(Dropout(0.15))\n\ncnn_model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\ncnn_model.add(MaxPooling1D(pool_size=2))\ncnn_model.add(Dropout(0.15))\n\ncnn_model.add(Flatten())\ncnn_model.add(Dense(1))\n\ncnn_model.summary()\n\ncnn_model.compile(optimizer=\"adam\", loss=\"MSE\")\ncnn_model.fit(X_train, y_train, epochs=10, batch_size=80)\n\n# Make predictions using the CNN model\ncnn_predictions = cnn_model.predict(X_test)\n\n# Convert predictions and actual values to binary classes (1 for anomaly, 0 for normal)\nthreshold_high = 0.5\ncnn_pred_classes = (cnn_predictions > threshold_high).astype(int)\ny_test_class = (y_test > threshold_high).astype(int)\n\n# Evaluation metrics\ncnn_r2 = r2_score(y_test, cnn_predictions)\ncnn_conf_matrix = confusion_matrix(y_test_class, cnn_pred_classes)\n\nprint(\"CNN Model R2 Score:\", cnn_r2)\nprint(\"Confusion Matrix:\")\nprint(cnn_conf_matrix)\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test_class, cnn_pred_classes))\n\n# Plot confusion matrix\nplt.figure(figsize=(6, 6))\nsns.heatmap(cnn_conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 14})\nplt.title('Confusion Matrix - CNN Model')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-02T03:07:02.553967Z","iopub.status.idle":"2024-02-02T03:07:02.554917Z"},"trusted":true},"execution_count":null,"outputs":[]}]}